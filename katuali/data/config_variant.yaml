# Master katuali configuration file template
# ------------------------------------------
#
# Having copied this file with the command:
#     katuali_config my_config.yaml
# it will be necessary to amend the `DATA:` dictionary in the first section below
# to define the dataset to be processed.
#
# The second section containing software locations should also be checked and
# amended if necessary.
#
# To run the predefined workflows: `all_fast_assm_polish`, `all_standard_assm_polish`
# `all_medaka_train_features` starting from fast5 input,
# nothing else need be done. If starting a workflow from basecall data
# (https://nanoporetech.github.io/katuali/examples.html#starting-from-existing-basecalls),
# basecalls should be placed under the basecalling folder as defined in the pipelines config section.
# For the all_fast_assm_polish pipeline for example, basecalls should be placed in 
# "{DATA}/guppy/basecalls.fastq"


####################
# Input data options

# .fast5 files can be under top-level folders named by a RUNID (these need not
# be actual run UUIDs). Fast5s should be in RUNID/reads.  The keys within this
# data dictionary are RUNIDs.
#
# REFERENCE is required for the medaka training workflows, and in general any
# time reads need to be aligned to a reference (e.g. for for subsampling)
#   
# MEDAKA_TRAIN_REGIONS and MEDAKA_EVAL_REGIONS define regions for
# training and evaluation within the medaka training workflow, and are
# otherwise not used. 
#
# GENOME_SIZE is required only in workflows using the canu or flye assembler.
# When a reference file is given, GENOME_SIZE will be calculated from it in
# the case that a value is not directly specified.
#
# In the example below we train from the "minion" run using "ecoli" and "yeast"
# contigs in the reference and evaluate on the "gridion" run using the contigs
# "ecoli", "yeast" and "na12878_chr21" in the reference.


DATA:
    'dna_prom':
        # For variant-calling training datasets, do not change the reference path.
        # Either link to a pre-existing file or let katuali download the reference.
        'REFERENCE': 'medaka_variant_resources/grch38/grch38.fna.gz'
        # for variant calling MEDAKA_TRAIN_REGIONS could be entire chromomosomes
        'MEDAKA_TRAIN_REGIONS': ['chr15', 'chr16', 'chr17', 'chr18', 'chr19']
        'MEDAKA_EVAL_REGIONS': []
        'SAMPLE': "NA24385"


############################
# References and truth data required for variant calling training
# 
# SAMPLES: The GIAB NA24385 sample is shown here for example. Other or further samples
# can be used. 
#   - The truth reference MUST be provided under medaka_variant_resources/grch38/{SAMPLE}/
#     as {SAMPLE}.fasta (e.g. medaka_variant_resources/grch38/NA24385/NA24385.fasta)
#      -  The per chromosome truth references will be created by Katuali during runtime 
#         if they do not exist. They can be also linked or copied under 
#         medaka_variant_resources/grch38/{SAMPLE}/{SAMPLE}_per_chr/
#         as chrX.fasta, chrX_{SAMPLE}_maternal.fasta and chrX_{SAMPLE}_paternal.fasta
#      
#   - The high confidences bedfiles and vcfs for each sample can to be downloaded from the GIAB website
#     during runtime by providing the URLs as shown below for NA24385. Alternatively, bed and vcf files can
#     copied (or linked) to medaka_variant_resources/grch38/{SAMPLE}/{SAMPLE}_high_conf.bed 
#     and medaka_variant_resources/grch38/{SAMPLE}/{SAMPLE}_high_conf.vcf.gz, respectively. 
#
# VARIANTS_TO_ADD: Variant calls from 1k genomes project are used by default and will be downloaded 
# during runtime if the vcfs does not exist under medaka_variant_resources/grch38/1kgenomes/.
# A different set of variants can be added to the reference by replacing the filepath specified below. 
# A vcf must be provided per chromosome and a wildcard (chrX) for the chromosome needs to be contained 
# within the filename.
#
# See the documentation for further details on the Katuali directory structures for variant calling

VARIANT_RESOURCES:
    "SAMPLES":
        "NA24385":
            "TRUTH_HIGH_CONF_BED_URL": "https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/AshkenazimTrio/HG002_NA24385_son/NISTv3.3.2/GRCh38/HG002_GRCh38_GIAB_highconf_CG-Illfb-IllsentieonHC-Ion-10XsentieonHC-SOLIDgatkHC_CHROM1-22_v.3.3.2_highconf_noinconsistent.bed" 
            "TRUTH_HIGH_CONF_VCF_URL": "https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/AshkenazimTrio/HG002_NA24385_son/NISTv3.3.2/GRCh38/HG002_GRCh38_GIAB_highconf_CG-Illfb-IllsentieonHC-Ion-10XsentieonHC-SOLIDgatkHC_CHROM1-22_v.3.3.2_highconf_triophased.vcf.gz" 

    "VARIANTS_TO_ADD": "medaka_variant_resources/grch38/1kgenomes/ALL.{chr}.shapeit2_integrated_snvindels_v2a_27022019.GRCh38.phased.vcf.gz"

 


############################
# Definitions of standard pipelines
#
# For advanced users, these act as shortcuts for creating batches of similar
# targets en-masse.
#
# Pipeline target template definitions containing other config parameters that
# will be filled in with config variables to generate targets, see
# documentation for full details.  

PIPELINES:
    all_medaka_snp_feat: [
        "{DATA}/guppy_hac_prom/align/{MEDAKA_TRAIN_REGIONS}/{SNP_DEPTHS}X_prop/medaka_diploid_snp_features/{DATA}_{MEDAKA_TRAIN_REGIONS}_{SNP_DEPTHS}X_medaka_train.hdf",

    ]
    all_medaka_variant_feat: [
        "{DATA}/guppy_hac_prom/align/{MEDAKA_TRAIN_REGIONS}/calls2scuffed_ref/{DEPTHS}X_prop/medaka_features/medaka_train_variant_{DATA}_{MEDAKA_TRAIN_REGIONS}_{DEPTHS}X.hdf",
        "{DATA}/guppy_hac_prom/align/{MEDAKA_TRAIN_REGIONS}/calls2scuffed_ref/{DEPTHS}X_prop/medaka_features/medaka_train_variant_{DATA}_{MEDAKA_TRAIN_REGIONS}_{DEPTHS}X_rc.hdf"
    ]
    all_medaka_variant_resources: [
        "medaka_variant_resources/grch38/{SAMPLE}/{SAMPLE}.fasta.gz",
        "medaka_variant_resources/grch38/{SAMPLE}/{SAMPLE}_per_chr_diploid/{MEDAKA_TRAIN_REGIONS}.fasta.gz",
        "medaka_variant_resources/grch38/{SAMPLE}/{SAMPLE}_per_chr_diploid/{MEDAKA_TRAIN_REGIONS}_{SAMPLE}_paternal.fasta.gz",
        "medaka_variant_resources/grch38/{SAMPLE}/{SAMPLE}_per_chr_diploid/{MEDAKA_TRAIN_REGIONS}_{SAMPLE}_maternal.fasta.gz",
        "medaka_variant_resources/grch38/{SAMPLE}/{MEDAKA_TRAIN_REGIONS}/diploid_truth_to_ref.bam",
        "medaka_variant_resources/grch38/{SAMPLE}/{MEDAKA_TRAIN_REGIONS}/truth_to_scuffed_ref_mat.bam",
        "medaka_variant_resources/grch38/{SAMPLE}/{MEDAKA_TRAIN_REGIONS}/truth_to_scuffed_ref_pat_rc.bam",
        "medaka_variant_resources/grch38/{SAMPLE}/filtered_beds/{MEDAKA_TRAIN_REGIONS}_filtered_hc.bed",
    ]


# Runtime configuration
RUNTIME:  
    # default number of threads/cores/slots to use per multi-threaded task.
    THREADS_PER_JOB: 8
    # To run medaka consensus on GPU, set MEDAKA_CONSENSUS_NUM_GPU to 1.
    # More than a single GPU is not currently supported (by medaka).
    MEDAKA_CONSENSUS_NUM_GPU: 0

    ##############################
    # Location of various software
    #
    # Configuration for software is found toward the end of this config.
    IN_MEDAKA: "~/git/medaka/venv/bin/activate"
    IN_POMOXIS: "~/git/pomoxis/venv/bin/activate"
    CANU_EXEC: "~/git/canu-1.8/Linux-amd64/bin/canu"
    FLYE_EXEC: "~/git/Flye/bin/flye"
    SHASTA_EXEC: "~/git/shasta-Linux-0.3.0"
    GUPPY_EXEC: "/usr/bin/guppy_basecaller"
    PORPITA_EXEC: "~/git/porpita/porpita"
    SOURCE: "source"
    LIFTOVER: "~/miniconda3/envs/liftover/bin/liftOver"
    VCFCREATEMULTI: "~/git/vcflib/bin/vcfcreatemulti"
    LD_LIBRARY_PATH: ""  # set this for e.g. CUDA library path

    #########################
    # Compute/cluster options

    # Location of scratch space on cluster nodes. This is currently only used for
    # medaka training where latency on an networked filesystem can significantly
    # slow things down. To have katuali copy medaka features to scratch space
    # before training set SCRATCH and optionally TMPSCRATCH.
    #
    # If TMPSCRATCH is given the resultant path will be:
    #     /SCRATCH/$USER/TMPSCRATCH
    # whereas if it is not given the resultant path will be:
    #    /SCRATCH/$USER/<generated unique name>
    #
    # TMPSCRATCH is useful in the case of restarting a training job on a node to
    # which features have already been copied; in this case, simply set TMPSCRATCH
    # to the directory under which the features were copied and katuali will skip
    # copying the data and use the existing data.
    #
    # Note that katuali does not delete the data in scratch, so users must do this
    # manually.
    SCRATCH: ""
    TMPSCRATCH: ""

    # Snakemake checks for the existence of input files on the submission node.  On
    # systems with a high-latency distributed file system, the existence of a file
    # on the submission node may not guarantee its presence on a compute node.
    # Katuali checks that all input files exist on the machine where a rule is
    # about to run.  Note that if the file is not found, katuali will attempt to
    # force an NFS cache update by changing the owner of the file to the current
    # user (using chown). If the file is still not found, execution terminates.
    # Verbose logging of the file checking can by setting CHECK_FILES_EXIST_OPTS to
    # '--debug'. 
    #CHECK_FILES_EXIST_OPTS: '--debug'  # activate logging of file-checking
    CHECK_FILES_EXIST_OPTS: '--quiet'  # check files silently


############################
# Misc. options for programs
#
# For advanced users. See
# https://nanoporetech.github.io/katuali/examples.html#examples
# for help in contructing bespoke pipelines.
#
# For fully specified targets, rather than predefined workflows the below can
# be used to manipulate how each program is run. Each key acts as a shortcut
# for a specific parameter set (as well as functioning as a target name).
# Default parameters are given by the `""` targets

# Guppy        
GUPPY_OPTS: 
    "": "-c dna_r9.4.1_450bps_hac.cfg"
    "_hac": "-c dna_r9.4.1_450bps_hac.cfg"
    "_hac_prom": "-c dna_r9.4.1_450bps_hac_prom.cfg"
    "_fast": "-c dna_r9.4.1_450bps_fast.cfg"
    "_fast_prom": "-c dna_r9.4.1_450bps_fast_prom.cfg"

# subsample_bam
SUBSAMPLE_BAM_OPTS:
    "": "--all_fail"
    "_prop": "--proportional --all_fail"
    "_filtered": "--quality 6 --coverage 90 --all_fail"

# mini_align
MINI_ALIGN_OPTS:
    "": ""
    "_all": "-A"

# mini_assemble
MINI_ASSEMBLE_OPTS: 
    "": ""
    "_ce": "-c -e 10"
    "_ces": "-c -e 10 -n 10"

# porpita 
PORPITA_OPTS: 
    "": ""

# Canu 
CANU_EXEC_OPTS:
    "useGrid=False" # this shouldn't be changed, snakemake will be confused
CANU_OPTS:
    "": "" 

# Flye 
FLYE_OPTS:
    "": "" 

# Shasta 
SHASTA_OPTS:
    "": "--Reads.minReadLength 2000"

# assess_assembly
ASSESS_ASSM_SUFFIXES: [""]
ASSESS_ASSM_OPTS:
    "": "-C -H" # runs cataloguing of errors and homopolymer analysis


#############################
# Options for medaka training

# This section can be ignored if not running a medaka training workflow

# Read depths at which to create pileups for training, this should
# span the range of depths at which the model is to be used
DEPTHS:  # for haploid variant calling 
    [10, 15, 20, 25, 30]
SNP_DEPTHS:  # for diploid, hence double the depth
    [20, 30, 40, 50, 60]

# If any medaka feature files are missing (e.g. due to insufficient coverage
# for some runs / contigs) the medaka training step will not find all the files
# it expects and will not run. To train on the feauture files which were
# created, set this flag to true (after having already created the features
# with the flag set to false) 
USE_ONLY_EXISTING_MEDAKA_FEAT:
    false

# Run multiple training replicates - output will be in medaka_train_{key},
# values should be a key of the PIPELINES dictionary in this file. In simple
# cases this allows running technical replicates of the training, but also
# allows the pipeline to be changed to for example create features in a
# different manner. For the latter change the value component to an alternative
# user defined pipeline.
MEDAKA_TRAIN_REPLICATES:
    "_snp_rep_1": "all_medaka_snp_feat" 
    "_snp_rep_2": "all_medaka_snp_feat"
    "_snp_rep_3": "all_medaka_snp_feat"
    "_variant_rep_1": "all_medaka_variant_feat" 
    "_variant_rep_2": "all_medaka_variant_feat"
    "_variant_rep_3": "all_medaka_variant_feat"

# Evaluation of trained models, entries in this list should be keys
# of MEDAKA_OPTS, the values of which need to specify the path of the
# trained model using the `-m option`.
MEDAKA_EVAL_SUFFIXES:
    ["_rep_1_best_val", "_rep_2_best_val", "_rep_3_best_val"]
MEDAKA_OPTS:
    "": "-m r941_min_high_g344"
    "_hac": "-m r941_min_high_g344"
    "_hac_prom": "-m r941_prom_high_g344"
    "_fast": "-m r941_min_fast_g303"
    "_fast_prom": "-m r941_prom_fast_g303"
    "_rep_1_best_val": "-m medaka_train_rep_1/model.best.val_cat_acc.hdf5"
    "_rep_2_best_val": "-m medaka_train_rep_2/model.best.val_cat_acc.hdf5"
    "_rep_3_best_val": "-m medaka_train_rep_3/model.best.val_cat_acc.hdf5"

# Medaka training features
MEDAKA_TRAIN_FEAT_OPTS:
    "": "--chunk_len 1000 --chunk_ovlp 0"

MEDAKA_TRAIN_OPTS:
    "_snp_rep_1": " --optim_args lr=0.0001 rho=0.9 epsilon=None decay=0.0"
    "_snp_rep_2": " --optim_args lr=0.0001 rho=0.9 epsilon=None decay=0.0"
    "_snp_rep_3": " --optim_args lr=0.0001 rho=0.9 epsilon=None decay=0.0"
    "_variant_rep_1": " --optim_args lr=0.0001 rho=0.9 epsilon=None decay=0.0"
    "_variant_rep_2": " --optim_args lr=0.0001 rho=0.9 epsilon=None decay=0.0"
    "_variant_rep_3": " --optim_args lr=0.0001 rho=0.9 epsilon=None decay=0.0"

# Setting MEDAKA_TRAIN_SNP_USE_BED to True restricts MEDAKA SNP-calling
# training data to high-confident regions
MEDAKA_TRAIN_SNP_USE_BED: True
