from functools import partial
import itertools
import os
import sys

import katuali

KATUALI_VERSION = katuali.__version__

GUPPY_EXEC = os.path.expanduser(config["GUPPY"])
NANOPOLISH_EXEC = os.path.join(os.path.expanduser(config["NANOPOLISH"]), "nanopolish")
NANOPOLISH_MAKE_RANGE = os.path.join(os.path.expanduser(config["NANOPOLISH"]), "scripts", "nanopolish_makerange.py")
IN_POMOXIS = os.path.expanduser(config["IN_POMOXIS"])
IN_MEDAKA = os.path.expanduser(config["IN_MEDAKA"])
IN_MEDAKA_GPU = os.path.expanduser(config["IN_MEDAKA_GPU"])
CANU_EXEC = os.path.expanduser(config["CANU_EXEC"])
FLYE_EXEC = os.path.expanduser(config["FLYE_EXEC"])
SHASTA_EXEC = os.path.expanduser(config["FLYE_EXEC"])

# Always set the environment
LD_LIBRARY_PATH = config.get("LD_LIBRARY_PATH")
shell.prefix("export LD_LIBRARY_PATH=\"%s\"; " % (LD_LIBRARY_PATH))

config["THREADS_PER_JOB"] = int(config["THREADS_PER_JOB"])

# NOTE on virtual environments
# Snakemake uses bash strict mode, virtualenv violates bash strict mode.
# https://snakemake.readthedocs.io/en/stable/project_info/faq.html#my-shell-command-fails-with-with-errors-about-an-unbound-variable-what-s-wrong
# so any activation commands must be wrapped as such:
#      set +u; {config[IN_MEDAKA]}; set -u; 


rule version:
    run:
        print('katuali version {}'.format(KATUALI_VERSION))


rule help:
    shell:
        'echo See https://nanoporetech.github.io/katuali/examples.html for help in getting started'


rule environment:
    # Just output the contents of PATH and LD_LIBRARY_PATH to log
    log:
        "katuali.sge.log",
    resources:
        gpu = 0
    shell:
        'echo $PATH; echo $LD_LIBRARY_PATH'


def get_reference(wildcards, config):
    # return the absolute path so that a reference in the working directory
    # e.g. ref.fasta is not confused for a pipeline target, which is
    # distinguished from an explicit target by the lack of a '/' in pipeline targets.  
    return os.path.abspath(config["DATA"][wildcards["runid"]]["REFERENCE"])


def get_contig_opt(wildcards, config):
    if "REGIONS" in config and "REGIONS" != "":
        contig_opt = "-r {}".format(config["REGIONS"])
    elif wildcards.contig == "all_contigs":
        contig_opt = ""
    else:
        contig_opt = "-r {}".format(wildcards.contig)
    logger.run_info("Setting region option to {}".format(contig_opt))
    return contig_opt


def get_opts(wildcards, config, config_key):
    default_key = ''

    if config_key not in config:
        raise KeyError('{} not in config'.format(config_key))

    suffix = wildcards["suffix"]

    if not isinstance(config[config_key], dict):
        opts = config[config_key]
        logger.run_info("{} parameters were not nested, using {}".format(config_key, opts))

    elif suffix in config[config_key] and suffix != default_key:
        opts = config[config_key][suffix]
        logger.run_info("Using {} parameters specified by suffix {}".format(config_key, suffix))
    else:
        opts = config[config_key][default_key]
        logger.run_info("Using default {} parameters".format(config_key))

    return opts


rule basecall_guppy:
    input:
        guppy = ancient(GUPPY_EXEC),
        fast5 = ancient("{runid}/reads"),
        venv = ancient(IN_POMOXIS),
    output:
        fasta = "{runid}/basecall/guppy{suffix,[^/]*}/basecalls.fasta",
        summary = "{runid}/basecall/guppy{suffix,[^/]*}/sequencing_summary.txt",
    log:
        "{runid}/basecall/guppy{suffix,[^/]*}.log",
    params:
        output_dir = lambda w: "{runid}/basecall/guppy{suffix}".format(**dict(w)),
        opts = partial(get_opts, config=config, config_key="GUPPY_OPTS"),
    threads: 4
    resources:
        gpu = 1
    shell:
        """
        # snakemake will create the output dir, guppy will fail if it exists..
        rm -r {params[output_dir]}

        echo "GPU status before" >> {log}
        gpustat >> {log}

        sleep $(((RANDOM % 30)  + 1 ))

        GPU=$(pick_gpu 2>> {log})

        echo "Runnning on host $HOSTNAME GPU $GPU" >> {log}

        {input.guppy} -s {params.output_dir} -r -i {input.fast5} -x cuda:$GPU {params.opts} &>> {log}

        echo "gpustat after" >> {log}
        gpustat >> {log}

        # convert fastq to fasta
        sleep 5
        echo "Combining the following fastq files into {output.fasta}" >> {log}
        ls {params[output_dir]}/*.fastq >> {log}
        set +u; {config[SOURCE]} {input.venv}; set -u;
        seqkit fq2fa {params.output_dir}/*.fastq > {output.fasta}
        rm {params.output_dir}/*.fastq
        """


rule align_to_ref:
    input:
        venv = ancient(IN_POMOXIS),
        basecalls = ancient("{runid}/basecall/{bc_dir}/basecalls.fasta"),
        ref = ancient(partial(get_reference, config=config)),
    output:
        bam = "{runid}/basecall/{bc_dir}/align/calls2ref.bam"
    log:
        "{runid}/basecall/{bc_dir}/align/align_to_ref.log"
    params:
        prefix = lambda w, output: os.path.splitext(output.bam)[0],
    threads: config["THREADS_PER_JOB"]
    resources:
        gpu = 0
    shell:
        """
        set +u; {config[SOURCE]} {input.venv}; set -u;
        mini_align -i {input.basecalls} -r {input.ref} -p {params.prefix} -P -t {threads} &> {log}
        """


rule align_to_draft:
    input:
        venv = ancient(IN_POMOXIS),
        basecalls = ancient("{dir}/{subdir}/basecalls.fasta"),
        draft = ancient("{dir}/consensus.fasta"),
    output:
        bam = "{dir}/{subdir}/calls2draft.bam"
    log:
        "{dir}/{subdir}/align_to_draft.log"
    threads: config["THREADS_PER_JOB"]
    resources:
        gpu = 0
    shell:
        """
        set +u; {config[SOURCE]} {input.venv}; set -u;
        mini_align -i {input.basecalls} -r {input.draft} -p {wildcards.dir}/{wildcards.subdir}/calls2draft -P -t {threads} &> {log}
        """


rule assess_consensus:
    input:
        venv = ancient(IN_POMOXIS),
        consensus = ancient("{runid}/{dir}/consensus.fasta"),
        truth = ancient(partial(get_reference, config=config)),
    output:
        summ = "{runid,[^/]+}/{dir}/consensus_to_truth_summ.txt",
        bam = "{runid,[^/]+}/{dir}/consensus_to_truth.bam",
        stats = "{runid,[^/]+}/{dir}/consensus_to_truth_stats.txt",
    log:
        "{runid}/{dir}/assess_consensus.log"
    params:
        prefix = "{runid}/{dir}/consensus_to_truth",
    threads: config["THREADS_PER_JOB"]
    resources:
        gpu = 0
    shell:
        """
        set +u; {config[SOURCE]} {input.venv}; set -u;
        assess_assembly -i {input.consensus} -r {input.truth} -p {params.prefix} -t {threads} {config[ASSESS_ASSM_OPTS]} &> {log}
        """


rule get_depth:
    input:
        venv = ancient(IN_POMOXIS),
        bam = ancient("{dir}/calls2ref.bam"),
    output:
        depth = directory("{dir}/depth")
    log:
        "{dir}/depth/get_depth.log"
    params:
        contig_opt = partial(get_contig_opt, config=config),
    resources:
        gpu = 0
    shell:
        """
        set +u; {config[SOURCE]} {input.venv}; set -u;
        mkdir -p {output.depth} && coverage_from_bam {input.bam} {params.contig_opt} -s 1000 -p {output.depth}/ &> {log}
        """


rule get_basecall_stats:
    input:
        venv = ancient(IN_POMOXIS),
        bam = ancient("{dir}/calls2ref.bam"),
    output:
        stats = "{dir}/calls2ref_stats.txt"
    log:
        "{dir}/basecall_stats.log"
    resources:
        gpu = 0
    shell:
        """
        set +u; {config[SOURCE]} {input.venv}; set -u;
        stats_from_bam {input.bam} -o {output.stats} &> {log}
        """


rule subsample_bam:
    input:
        venv = ancient(IN_POMOXIS),
        bam = ancient("{dir}/calls2ref.bam"),
    output:
        fasta = "{dir}/{contig}/{depth,[0-9]+}X{suffix,[^/]*}/basecalls.fasta",
    log:
        "{dir}/{contig}/{depth}X{suffix}/subsample.log"
    params:
        contig_opt = partial(get_contig_opt, config=config),
        prefix = lambda w: "{dir}/{contig}/{depth}X{suffix}/sub_sample".format(**dict(w)),
        opts = partial(get_opts, config=config, config_key="SUBSAMPLE_BAM_OPTS"),
    resources:
        gpu = 0
    shell:
        """
        set +u; {config[SOURCE]} {input.venv}; set -u;
        subsample_bam {input.bam} {wildcards.depth} {params[contig_opt]} -o {params[prefix]} {params[opts]} -t {threads} &>{log};
        sleep 5;
        for i in {params[prefix]}*.bam; do samtools fasta $i ; done > {output.fasta}
        """


rule racon:
    input:
        venv = ancient(IN_POMOXIS),
        draft = ancient("{dir}/consensus.fasta"),
        basecalls = ancient("{dir}/basecalls.fasta"),
    output:
        consensus = "{dir}/racon{suffix,[^/]*}/consensus.fasta",
        basecalls = "{dir}/racon{suffix,[^/]*}/basecalls.fasta"
    log:
        "{dir}/racon{suffix}.log"
    params:
        output_dir = lambda w: "{dir}/racon{suffix}".format(**dict(w)),
        opts = partial(get_opts, config=config, config_key="MINI_ASSEMBLE_OPTS"),
    threads: config["THREADS_PER_JOB"]
    resources:
        gpu = 0
    shell:
        """
        set +u; {config[SOURCE]} {input.venv}; set -u;
        # snakemake will create the output dir, mini_assemble will fail if it exists..
        rm -r {params[output_dir]} &&
        mini_assemble -i {input.basecalls} -r {input.draft} -o {params[output_dir]} -t {threads} -p assm {params[opts]} &> {log}
        # rename output
        mv {params[output_dir]}/assm_final.fa {output.consensus}
        # keep a link of basecalls with the consensus
        ln -s $PWD/{input.basecalls} $PWD/{params[output_dir]}/basecalls.fasta
        """


rule ref_as_assembly_region:
    # Replace consensus with extracted reference for region.
    # 'region' must be in target 
    input:
        venv = ancient(IN_POMOXIS),
        basecalls = ancient("{runid}/{dir}/align/{region}/{depth}/basecalls.fasta"),
        truth = ancient(partial(get_reference, config=config)),
    output:
        basecalls = "{runid,[^/]+}/{dir}/align/{region,[^/]+}/{depth}/ref_assembly_gsz_{genome_size,[^/]*}/basecalls.fasta",
        consensus = "{runid,[^/]+}/{dir}/align/{region,[^/]+}/{depth}/ref_assembly_gsz_{genome_size,[^/]*}/consensus.fasta",
    log:
        "{runid}/{dir}/align/{region}/{depth}/ref_assembly_gsz_{genome_size}.log",
    params:
        output_dir = lambda w, output: os.path.dirname(output.basecalls),
    resources:
        gpu = 0
    shell:
        """
        set +u; {config[SOURCE]} {input.venv}; set -u;
        echo "Pulling region {wildcards.region} from {input.truth}" >>{log}
        samtools faidx {input.truth} {wildcards.region} > {output.consensus}
        sleep 5
        ln -s $PWD/{input.basecalls} $PWD/{params[output_dir]}/basecalls.fasta
        """


rule ref_as_assembly:
    # Replace consensus with full reference 
    input:
        venv = ancient(IN_POMOXIS),
        basecalls = ancient("{runid}/{dir}/basecalls.fasta"),
        truth = ancient(partial(get_reference, config=config)),
    output:
        consensus = "{runid,[^/]+}/{dir}/full_ref_assembly_gsz_{genome_size,[^/]*}/consensus.fasta",
        basecalls = "{runid,[^/]+}/{dir}/full_ref_assembly_gsz_{genome_size,[^/]*}/basecalls.fasta"
    log:
        "{runid}/{dir}/full_ref_assembly_gsz_{genome_size}.log"
    params:
        output_dir = lambda w, output: os.path.dirname(output.basecalls),
    resources:
        gpu = 0
    shell:
        """
        ln -s $PWD/{input.truth} $PWD/{output.consensus}
        ln -s $PWD/{input.basecalls} $PWD/{params.output_dir}/basecalls.fasta
        """

rule canu:
    # TODO can we make use of github.com/thiesgehrmann/FungalAssemblerPipeline ?
    input:
        canu = ancient(CANU_EXEC),
        basecalls = ancient("{dir}/basecalls.fasta"),
    output:
        consensus = "{dir}/canu{suffix,[^/]*}_gsz_{genome_size,[^/]*}/consensus.fasta",
        basecalls = "{dir}/canu{suffix,[^/]*}_gsz_{genome_size,[^/]*}/basecalls.fasta"
    log:
        "{dir}/canu{suffix}gsz_{genome_size}.log"
    params:
        gsz = lambda w: "genomeSize={genome_size}".format(**dict(w)),
        output_dir = lambda w, output: os.path.dirname(output.consensus),
        exec_opts = config["CANU_EXEC_OPTS"],
        opts = partial(get_opts, config=config, config_key="CANU_OPTS"),
        prefix = "canu",
        mt="maxThreads={}".format(config["THREADS_PER_JOB"]),
    threads: config["THREADS_PER_JOB"]
    resources:
        gpu = 0
    shell:
        """
        # snakemake will create the output dir, canu will fail if it exists..
        #rm -r {params[output_dir]}
        {input.canu} -d {params.output_dir} -p {params.prefix} {params.gsz} -nanopore-raw {input.basecalls} {params.exec_opts} {params[opts]} {params.mt} &> {log}
        mv {params.output_dir}/{params.prefix}.contigs.fasta {output.consensus} &&
        ln -s $PWD/{input.basecalls} $PWD/{params[output_dir]}/basecalls.fasta
        # remove canu intermediates we don't use
        rm -rf {params.output_dir}/{params.prefix}.* {params.output_dir}/correction {params.output_dir}/haplotyping {params.output_dir}/trimming {params.output_dir}/unitigging
        """


rule flye:
    input:
        flye = ancient(FLYE_EXEC),
        basecalls = ancient("{dir}/basecalls.fasta"),
    output:
        consensus = "{dir}/flye{suffix,[^/]*}_gsz_{genome_size,[^/]*}/consensus.fasta",
        basecalls = "{dir}/flye{suffix,[^/]*}_gsz_{genome_size,[^/]*}/basecalls.fasta"
    log:
        "{dir}/flye{suffix}gsz_{genome_size}.log"
    params:
        gsz = lambda w: "{genome_size}".format(**dict(w)),
        output_dir = lambda w, output: os.path.dirname(output.consensus),
        opts = partial(get_opts, config=config, config_key="FLYE_OPTS"),
        prefix = "flye",
        mt=config["THREADS_PER_JOB"],
    threads: config["THREADS_PER_JOB"]
    resources:
        gpu = 0
    shell:
        """
        {input.flye} --nano-raw {input.basecalls} --genome-size {params.gsz} --out-dir {params.output_dir} --threads {params.mt} {params[opts]} &> {log}
        mv {params.output_dir}/assembly.fasta {output.consensus} &&
        ln -s $PWD/{input.basecalls} $PWD/{params[output_dir]}/basecalls.fasta
        """


rule shasta:
    input:
        shasta = ancient(FLYE_EXEC),
        basecalls = ancient("{dir}/basecalls.fasta"),
    output:
        consensus = "{dir}/shasta{suffix,[^/]*}_gsz_{genome_size,[^/]*}/consensus.fasta",
        basecalls = "{dir}/shasta{suffix,[^/]*}_gsz_{genome_size,[^/]*}/basecalls.fasta"
    log:
        "{dir}/shasta{suffix}gsz_{genome_size}.log"
    params:
        gsz = lambda w: "{genome_size}".format(**dict(w)),
        output_dir = lambda w, output: os.path.dirname(output.consensus),
        opts = partial(get_opts, config=config, config_key="SHASTA_OPTS"),
        prefix = "shasta",
        mt=config["THREADS_PER_JOB"],
    threads: config["THREADS_PER_JOB"]
    resources:
        gpu = 0
    shell:
        """
        {input.shasta} --assemblyDirectory {params.output_dir} --threads {params.mt} {params[opts] &> {log}
        mv {params.output_dir}/Assembly.fasta {output.consensus} &&
        ln -s $PWD/{input.basecalls} $PWD/{params[output_dir]}/basecalls.fasta
        """

rule medaka_consensus:
    input:
        venv = ancient(IN_MEDAKA),
        draft = ancient("{dir}/consensus.fasta"),
        basecalls = ancient("{dir}/basecalls.fasta"),
    output:
        consensus = "{dir}/medaka{suffix,[^/]*}/consensus.fasta",
        basecalls = "{dir}/medaka{suffix,[^/]*}/basecalls.fasta"
    log:
        "{dir}/medaka{suffix}.log"
    threads: 8
    resources:
        # TODO: support either GPU or CPU, i.e. if we are using GPU we have to
        # run pick_gpu and export CUDA_VISIBLE_DEVICES=1, but not if we are
        # running on CPU
        gpu = 0
    params:
        opts = partial(get_opts, config=config, config_key="MEDAKA_OPTS"),
        output_dir = lambda w, output: os.path.dirname(output.consensus),
    shell:
        """
        set +u; {config[SOURCE]} {input.venv}; set -u;
        # snakemake will create the output dir if it does not exist, remove it it exists.
        rm -r {params[output_dir]}

        medaka_consensus -i {input.basecalls} -d {input.draft} -o {params[output_dir]} -t {threads} {params[opts]} &> {log}

        # keep a link of basecalls with the consensus
        ln -s $PWD/{input.basecalls} $PWD/{output.basecalls}
        # rm large intermediates
        rm {params[output_dir]}/calls_to_draft.bam* {params[output_dir]}/consensus_probs.hdf
        """


rule nanopolish_basecalls:
    # nanopolish index can't seem to cope with fasta headers
    input:
        ancient("{runid}/basecall/{subdir}/basecalls.fasta"),
    output:
        "{runid}/basecall/{subdir}/nanopolish/basecalls.fasta",
    log:
        "{runid}/basecall/{subdir}/nanopolish/nanopolish_basecalls.log"
    resources:
        gpu = 0
    shell:
        """
        cut -d' ' -f1 < {input} > {output} 2> {log}
        """


rule nanopolish_index:
    input:
        nanopolish = ancient(NANOPOLISH_EXEC),
        fast5 = ancient("{runid}/reads"),
        summary = ancient("{runid}/basecall/{basecaller}/sequencing_summary.txt"),
        basecalls = ancient("{runid}/basecall/{basecaller}/{subdir}/nanopolish/basecalls.fasta"),
    output:
        "{runid}/basecall/{basecaller,[^/]+}/{subdir}/nanopolish/basecalls.fasta.index",
        "{runid}/basecall/{basecaller,[^/]+}/{subdir}/nanopolish/basecalls.fasta.index.gzi",
        "{runid}/basecall/{basecaller,[^/]+}/{subdir}/nanopolish/basecalls.fasta.index.fai",
        "{runid}/basecall/{basecaller,[^/]+}/{subdir}/nanopolish/basecalls.fasta.index.readdb",
    log:
        "{runid}/basecall/{basecaller}/{subdir}/nanopolish/nanopolish_index.log"
    resources:
        gpu = 0
    shell:
        """
        {input.nanopolish} index -d {input.fast5} -s {input.summary} {input.basecalls} &> {log}
        """


rule fast5_list:
    input:
        fast5 = ancient("{runid}/reads")
    output:
        filelist = "{runid}/reads/reads.txt"
    log:
        "{runid}/reads/fast5_list.log"
    resources:
        gpu = 0
    shell:
        """
        find -L `readlink -f {input.fast5}` -name '*.fast5' > {output.filelist} &> {log}
        """


rule nanopolish_vcf:
    input:
        nanopolish = ancient(NANOPOLISH_EXEC),
        draft = ancient("{dir}/consensus.fasta"),
        basecalls = ancient("{dir}/nanopolish/basecalls.fasta"),
        bam = ancient("{dir}/nanopolish/calls2draft.bam"),
        index = ancient("{dir}/nanopolish/basecalls.fasta.index"),
        index_gzi = ancient("{dir}/nanopolish/basecalls.fasta.index.gzi"),
        index_fai = ancient("{dir}/nanopolish/basecalls.fasta.index.fai"),
        index_readdb = ancient("{dir}/nanopolish/basecalls.fasta.index.readdb"),
    output:
        vcf = "{dir}/nanopolish/regions/{region}.vcf",
    log:
        "{dir}/nanopolish/regions/{region}.vcf.log"
    params:
        # wildcards in dynamic files cannot be constrained => we can't safely extract a
        # suffix from dynamic nanopolish targets to use to use nested config
        opts = config["NANOPOLISH_OPTS"],
    resources:
        gpu = 0
    shell:
        """
        {input.nanopolish} variants --consensus -o {output.vcf} -w {wildcards.region} -r {input.basecalls} -b {input.bam} -g {input.draft} -t 1 {params.opts} &> {log}
        """


rule nanopolish_regions:
    input:
        # use pomoxis python as this has all requirements of the script
        venv = ancient(IN_POMOXIS),
        make_range = ancient(NANOPOLISH_MAKE_RANGE),
        draft = ancient("{dir}/consensus.fasta"),
    output:
        # Number of regions is unknown ahead of time, so use dynamic keyword to delay evaluation
        regions = dynamic("{dir}/nanopolish/regions/{region}.region"),
    params:
        # seemingly to have a regular log, we would need one per region..
        log = "{dir}/nanopolish/regions/nanopolish_regions.log"
    resources:
        gpu = 0
    shell:
        """
        set +u; {config[SOURCE]} {input.venv}; set -u;
        python {input.make_range} {input.draft} > {wildcards.dir}/nanopolish/regions.list 2> {params.log} &&
        for i in `cat {wildcards.dir}/nanopolish/regions.list`; do touch {wildcards.dir}/nanopolish/regions/$i.region; done 2>> {params.log}
        """


rule nanopolish:
    input:
        nanopolish = ancient(NANOPOLISH_EXEC),
        draft = ancient("{dir}/consensus.fasta"),
        # Number of regions is unknown ahead of time, so use dynamic keyword to delay evaluation
        regions = ancient(dynamic("{dir}/nanopolish/regions/{region}.region")),
        vcfs = ancient(dynamic("{dir}/nanopolish/regions/{region}.vcf")),
    output:
        consensus = "{dir}/nanopolish/consensus.fasta",
    log:
        "{dir}/nanopolish/vcf2fasta.log"
    resources:
        gpu = 0
    shell:
        "{input.nanopolish} vcf2fasta -g {input.draft} {input.vcfs} > {output.consensus} 2> {log}"


rule medaka_train_features:
    input:
        in_medaka = ancient(IN_MEDAKA),
        in_pomoxis = ancient(IN_POMOXIS),
        draft = ancient("{runid}/basecall/{bc}/align/{region}/{dir}/consensus.fasta"),
        basecalls = ancient("{runid}/basecall/{bc}/align/{region}/{dir}/basecalls.fasta"),
        truth = ancient(partial(get_reference, config=config)),
    output:
        features = "{runid,[^/]+}/basecall/{bc,[^/]+}/align/{region,[^/]+}/{dir}/medaka_features{suffix,[^/]*}/medaka_train.hdf",
        rc_features = "{runid,[^/]+}/basecall/{bc,[^/]+}/align/{region,[^/]+}/{dir}/medaka_features{suffix,[^/]*}/medaka_train_rc.hdf",
    log:
        "{runid}/basecall/{bc}/align/{region}/{dir}/medaka_features{suffix}.log"
    threads: config["THREADS_PER_JOB"]
    resources:
        gpu = 0
    params:
        output_dir = lambda w, output: os.path.dirname(output.features),
        bam = lambda w, output: os.path.join(os.path.dirname(output.features), "calls2ref"),
        truth_bam = lambda w, output: os.path.join(os.path.dirname(output.features), "truth2ref"),
        rc_bam = lambda w, output: os.path.join(os.path.dirname(output.features), "callsrc2ref"),
        rc_truth_bam = lambda w, output: os.path.join(os.path.dirname(output.features), "truth2refrc"),
        rc_draft = lambda w, output: os.path.join(os.path.dirname(output.features), "draftrc.fasta"),
        truth_region = lambda w, output: os.path.join(os.path.dirname(output.features), "truth.fasta"),
        opts = partial(get_opts, config=config, config_key="MEDAKA_TRAIN_FEAT_OPTS"),
        truth_chunk = config["MEDAKA_TRAIN_TRUTH_CHUNK"],
    shell:
        """
        set +u; {config[SOURCE]} {input.in_pomoxis}; set -u;

        # keep a link of basecalls with the consensus

        ln -sf $PWD/{input.basecalls} $PWD/{params.output_dir}/basecalls.fasta
        sleep 1

        echo "aligning basecalls to draft" >{log}
        mini_align -i {input.basecalls} -r {input.draft} -p {params.bam} -t {threads} -P -m &>> {log}
        sleep 5

        echo "Extracting truth region {wildcards.region} from reference" >>{log}
        samtools faidx {input.truth} {wildcards.region} > {params.truth_region} 2>> {log}
        sleep 5

        echo "aligning truth to draft" >>{log}
        mini_align -i {params.truth_region} -r {input.draft} -p {params.truth_bam} -t {threads} -P -m -c {params.truth_chunk} &>> {log}
        sleep 5

        echo "reverse complement the draft and align reads" >> {log}
        seqkit seq --complement --reverse {input.draft} -o {params.rc_draft} &>> {log}
        sleep 5

        echo "aligning basecalls to rc draft" >>{log}
        mini_align -i {input.basecalls} -r {params.rc_draft} -p {params.rc_bam} -t {threads} -P -m &>> {log}
        sleep 5

        echo "aligning truth to rc draft" >> {log}
        mini_align -i {params.truth_region} -r {params.rc_draft} -p {params.rc_truth_bam} -t {threads} -P -m -c {params.truth_chunk} &>> {log}
        sleep 5

        echo "creating features" >> {log}
        set +u; {config[SOURCE]} {input.in_medaka} set -u;
        medaka features {params.bam}.bam {output.features} --truth {params.truth_bam}.bam {params[opts]} --threads {threads} &>> {log}
        echo "creating rc features"
        medaka features {params.rc_bam}.bam {output.rc_features} --truth {params.rc_truth_bam}.bam {params[opts]} --threads {threads} &>> {log}

        """


def get_medaka_train_features(wildcards, config=config):
    # The `MEDAKA_TRAIN_REPLICATES` section of the config specifies
    # a set of training replicates and the PIPELINE required to create the
    # features for these replicates. The PIPELINE itself is simply a list of
    # target templates. The function `expand_target_template` used below
    # fills in the template using values from the DATA section of the config
    # in all possible ways.
    features_pipeline = config["MEDAKA_TRAIN_REPLICATES"][wildcards["suffix"]]
    feature_templates = config["PIPELINES"][features_pipeline]
    targets = []
    for template in feature_templates:
        targets.extend(katuali.expand_target_template(template, config))

    if config["USE_ONLY_EXISTING_MEDAKA_FEAT"]:
        logger.run_info("WARNING: USE_ONLY_EXISTING_MEDAKA_FEAT set to true, only using existing medaka training features.")
        n_all_feat = len(targets)
        targets = [f for f in targets if os.path.isfile(f)]
        if len(targets) == 0:
            raise ValueError("USE_ONLY_EXISTING_MEDAKA_FEAT set to true in config, but no features were found")
        logger.run_info("Found {}/{} of the medaka training feature files.".format(len(targets), n_all_feat))

    return targets


rule medaka_train:
    input:
        venv = ancient(IN_MEDAKA_GPU),
        features = ancient(partial(get_medaka_train_features, config=config))
    output:
        train_dir = directory("medaka_train_{suffix,[^/]*}")
    log:
        "medaka_train_{suffix}.log",
    params:
        opts = partial(get_opts, config=config, config_key="MEDAKA_TRAIN_OPTS"),
    threads: config["MEDAKA_TRAIN_THREADS_IO"]
    resources:
        gpu = 1
    shell:
        """
        echo "GPU status before" >> {log}
        gpustat >> {log}

        GPU=$(pick_gpu 2>> {log})

        echo "Runnning on host $HOSTNAME GPU $GPU" >> {log}

        if [ "{config[SCRATCH]}" != "" ];then
            if [ "{config[TMPSCRATCH]}" != "" ];then
                tmpscr={config[TMPSCRATCH]}
                echo "Using provided TMPSCRATCH {config[TMPSCRATCH]}" >> {log}
                mkdir -p $tmpscr &>> {log}
            else
                userscr={config[SCRATCH]}/$USER
                mkdir -p $userscr 2>> {log}
                tmpscr=$(mktemp -d -p $userscr) &>> {log}
            fi
            t=$(date +"%T")
            echo "$t: Copying feature files to specified scratch directory: $tmpscr." >> {log}
            for f in {input.features}; do
                d=$tmpscr/$f
                t0=$(date +"%T")
                if [[ ! -e $d ]]; then
                    echo "$t0 Copying $d" >> {log}
                    mkdir -p $(dirname $d) && sleep 1 && cp $f $d &>> {log}
                    t1=$(date +"%T")
                    echo "$t1 Copied $d" >> {log}
                else
                    echo "Found existing file: $d" >> {log}
                fi
            done
            features=$(for f in {input.features}; do echo $tmpscr/$f; done)
        else
            features={input.features}
        fi

        set +u; {config[SOURCE]} {input.venv} set -u;
        CUDA_VISIBLE_DEVICES=$GPU medaka train $features --train_name {output.train_dir} {params.opts} --threads_io {threads} &>> {log}
        """

def pipeline_targets(wildcards, config=config):
    p = wildcards['pipeline']
    logger.run_info("Creating targets for pipeline: {}".format(p))
    targets = []
    for template in config['PIPELINES'][p]:
        targets.extend(katuali.expand_target_template(template, config))
    return targets


rule pipeline:
    input:
        targets = partial(pipeline_targets, config=config)
    output:
        "{pipeline,[^/]*}"
